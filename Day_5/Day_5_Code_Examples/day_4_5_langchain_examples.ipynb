{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q langchain openai\n",
        "!pip install -q langchain openai langchain_openai\n"
      ],
      "metadata": {
        "id": "C0Wwr9hb12iK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbca853-79d8-4db0-9a7f-757533ff7ea2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m61.4/70.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Define the prompt template\n",
        "template = \"\"\"\n",
        "You are a helpful assistant that answers questions about {topic}.\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"question\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Format the prompt with specific values\n",
        "\n",
        "formatted_prompt = prompt.format(topic=\"Cricket\", question=\"Who is Ravi Shastri? and What roles in worked in?\")\n",
        "\n",
        "\n",
        "# Run the prompt through the model\n",
        "response = llm.invoke(formatted_prompt)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtkVQCpN1vAI",
        "outputId": "747a4f1e-d385-4ef5-d8fe-750abe5afcbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ravi Shastri is a former Indian cricketer and current head coach of the Indian national cricket team. He played as an all-rounder for the Indian team from 1981 to 1992. After his retirement, he worked as a commentator and cricket analyst before being appointed as the head coach in 2017. He has also served as the director of the Indian cricket team and as a member of the ICC Cricket Committee.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = input(\"Enter the topic: \")\n",
        "question = input(\"Enter the question: \")\n",
        "\n",
        "formatted_prompt = prompt.format(topic=topic, question=question)\n",
        "\n",
        "response = llm.invoke(formatted_prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjq-LJp15xJ",
        "outputId": "1bd41d03-499e-46b2-b203-df82ca19bec7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic: bollywood\n",
            "Enter the question: who is Big B\n",
            "\n",
            "Big B is a nickname for Amitabh Bachchan, a legendary actor in Bollywood known for his iconic roles and contributions to the Indian film industry. He is often referred to as the \"Shahenshah of Bollywood\" and has been a prominent figure in the industry for over five decades.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat Template Example Below"
      ],
      "metadata": {
        "id": "zbPs4EcX2xOz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CHHSgN2p35nA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "\n",
        "# ✅ Template with {topic} and {question}\n",
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "topic = input(\"Enter the topic: \")\n",
        "question = input(\"Enter the question: \")\n",
        "\n",
        "formatted_chat_prompt = chat_template.format_messages(topic=topic, question=question)\n",
        "\n",
        "chat_response = llm.invoke(formatted_chat_prompt)\n",
        "\n",
        "# Access the content attribute to get the response text\n",
        "print(chat_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oBtxrGp3eO-",
        "outputId": "1f0eb96f-0c6d-4cdc-a5e7-77c5bfea3818"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic: gen-ai\n",
            "Enter the question: do LLM store the questions asked by users? Are these determenestic?\n",
            "LLM (Large Language Models) do not store the questions asked by users in the traditional sense. They operate by processing and generating text based on the input they receive in real-time. The responses generated by LLMs are not deterministic in the sense that they can vary based on the specific input provided and the model's training data. While LLMs can exhibit consistent behavior for the same input, they are not deterministic in the strict sense of always producing the exact same output for a given input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the OpenAI model\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "\n",
        "# ✅ Template with {topic} and {question}\n",
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "topic = input(\"Enter the topic: \")\n",
        "question = input(\"Enter the question: \")\n",
        "\n",
        "formatted_chat_prompt = chat_template.format_messages(topic=topic, question=question)\n",
        "\n",
        "chat_response = llm.invoke(formatted_chat_prompt)\n",
        "\n",
        "# Access the content attribute to get the response text\n",
        "print(chat_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3z6ZSeB4TAJ",
        "outputId": "109c6342-55a4-483c-ce5b-1454c1c7f469"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic: cricket\n",
            "Enter the question: who is mr 360\n",
            "\"Mr. 360\" is a nickname for the South African cricketer AB de Villiers. He is known for his innovative and unorthodox batting style, which allows him to play shots 360 degrees around the field. He is considered one of the most talented and versatile batsmen in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Ask for the topic once\n",
        "topic = input(\"Enter the topic: \")\n",
        "\n",
        "# Loop to ask multiple questions\n",
        "while True:\n",
        "    question = input(\"\\nEnter your question (or type 'exit' to quit): \")\n",
        "\n",
        "    if question.lower() in ['exit', 'quit']:\n",
        "        print(\"Exiting... Have a great day!\")\n",
        "        break\n",
        "\n",
        "    # Format and send the prompt\n",
        "    chat_template = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "            (\"human\", \"{question}\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    formatted_chat_prompt = chat_template.format_messages(topic=topic, question=question)\n",
        "    chat_response = llm.invoke(formatted_chat_prompt)\n",
        "\n",
        "    # Show the answer\n",
        "    print(\"\\nAnswer:\", chat_response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XjJXfYS6QbG",
        "outputId": "30a9b34f-c234-4fd4-e50c-ae157a58f2d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic: cricket\n",
            "\n",
            "Enter your question (or type 'exit' to quit): who is Ganguly\n",
            "\n",
            "Answer: Sourav Ganguly, also known as Dada, is a former Indian cricketer and captain of the Indian national team. He is considered one of the greatest Indian cricket captains and is known for his aggressive leadership style and batting prowess. Ganguly played a key role in shaping the Indian team into a competitive force in international cricket during his tenure as captain.\n",
            "\n",
            "Enter your question (or type 'exit' to quit): exit\n",
            "Exiting... Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple topics\n"
      ],
      "metadata": {
        "id": "V8a9bm5w7AYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "print(\"Welcome! You can ask questions on any topic.\")\n",
        "print(\"Type 'change topic' to switch topics or 'exit' to quit.\\n\")\n",
        "\n",
        "# Master loop for multiple topics\n",
        "run = True\n",
        "while run:\n",
        "    topic = input(\"Enter the topic you'd like to ask about: \")\n",
        "    if topic.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Inner loop for multiple questions under the same topic\n",
        "    while True:\n",
        "        question = input(\"\\nAsk your question (or type 'change topic' or 'exit'): \").strip().lower()\n",
        "\n",
        "        if question == 'exit' or question == 'quit':\n",
        "            print(\"Goodbye!\")\n",
        "            run = False  # safely exit both loops\n",
        "            break\n",
        "        elif question == 'change topic':\n",
        "            break\n",
        "\n",
        "        # Chat prompt template\n",
        "        chat_template = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "                (\"human\", \"{question}\")\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        formatted_chat_prompt = chat_template.format_messages(topic=topic, question=question)\n",
        "        chat_response = llm.invoke(formatted_chat_prompt)\n",
        "\n",
        "        print(\"\\nAnswer:\", chat_response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1NfrEPT8H1V",
        "outputId": "90815031-850b-4a81-9c44-87aa628a527d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! You can ask questions on any topic.\n",
            "Type 'change topic' to switch topics or 'exit' to quit.\n",
            "\n",
            "Enter the topic you'd like to ask about: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Chains\n",
        " # Example #1 Below"
      ],
      "metadata": {
        "id": "iXN7JdPl9GXS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set your API key as before\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Define the chat prompt template (system + human)\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Chain them together using the Runnable operator\n",
        "chain = prompt | llm\n",
        "\n",
        "print(\"Welcome! You can ask questions on any topic.\")\n",
        "print(\"Type 'change topic' to switch topics or 'exit' to quit.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    topic = input(\"Enter the topic you'd like to ask about: \")\n",
        "    if topic.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nAsk your question (or type 'change topic' or 'exit'): \").strip()\n",
        "        if question.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        elif question.lower() == 'change topic':\n",
        "            break\n",
        "\n",
        "        # Use the chain for inference (with dictionary input)\n",
        "        response = chain.invoke({\n",
        "            \"topic\": topic,\n",
        "            \"question\": question\n",
        "        })\n",
        "\n",
        "        print(\"\\nAnswer:\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hiJ-4oVykfP",
        "outputId": "5337b8fc-fde9-417f-9d87-9dc741a8a5ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! You can ask questions on any topic.\n",
            "Type 'change topic' to switch topics or 'exit' to quit.\n",
            "\n",
            "Enter the topic you'd like to ask about: cricket\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is ABD\n",
            "\n",
            "Answer: ABD refers to AB de Villiers, a former South African cricketer who is widely regarded as one of the best batsmen in the world. He is known for his innovative stroke play, versatility, and ability to score runs quickly in all formats of the game.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Ben Stokes\n",
            "\n",
            "Answer: Ben Stokes is an English cricketer who is considered one of the best all-rounders in the world. He is known for his aggressive batting, effective bowling, and exceptional fielding skills. Stokes has played a key role in many memorable performances for the England cricket team, including his heroics in the 2019 Cricket World Cup final and the 2019 Ashes series.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): what is Bazzball\n",
            "\n",
            "Answer: It seems like there might be a typo in your question. If you are referring to \"Bazzball,\" it is not a recognized term in cricket. If you have any other questions about cricket or need information on a specific topic, feel free to ask!\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #2"
      ],
      "metadata": {
        "id": "zYfNwI_X2fhJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# API key setup (same as before)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# A helper function to build conversation history text from memory\n",
        "def format_history(history):\n",
        "    # history is a list of (question, answer) tuples\n",
        "    if not history:\n",
        "        return \"No previous Q&A.\"\n",
        "    formatted = \"\"\n",
        "    for i, (q, a) in enumerate(history[-5:], start=1):  # last 5 pairs\n",
        "        formatted += f\"Q{i}: {q}\\nA{i}: {a}\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "# ChatPromptTemplate extended to include conversation history\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\n",
        "         \"You are a helpful assistant that answers questions about {topic}.\\n\"\n",
        "         \"Here is the recent conversation history:\\n\"\n",
        "         \"{history}\\n\"\n",
        "         \"Answer the next question carefully.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "chain = prompt | llm\n",
        "\n",
        "print(\"Welcome! You can ask questions on any topic.\")\n",
        "print(\"Type 'change topic' to switch topics or 'exit' to quit.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    topic = input(\"Enter the topic you'd like to ask about: \")\n",
        "    if topic.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    conversation_history = []  # to store Q&A pairs for current topic\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nAsk your question (or type 'change topic' or 'exit'): \").strip()\n",
        "        if question.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        elif question.lower() == 'change topic':\n",
        "            break\n",
        "\n",
        "        # Generate the formatted history text\n",
        "        history_text = format_history(conversation_history)\n",
        "\n",
        "        # Invoke chain, passing topic, question & history\n",
        "        response = chain.invoke({\n",
        "            \"topic\": topic,\n",
        "            \"history\": history_text,\n",
        "            \"question\": question\n",
        "        })\n",
        "\n",
        "        answer = response.content\n",
        "        print(\"\\nAnswer:\", answer)\n",
        "\n",
        "        # Save the Q&A pair to memory\n",
        "        conversation_history.append((question, answer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjTyKDAY2gYb",
        "outputId": "b8320dd5-d5d0-49bd-ffc4-828cffb3bc89"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! You can ask questions on any topic.\n",
            "Type 'change topic' to switch topics or 'exit' to quit.\n",
            "\n",
            "Enter the topic you'd like to ask about: cricket\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is SRT\n",
            "\n",
            "Answer: SRT stands for Sachin Ramesh Tendulkar, who is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. He is known for his numerous records and achievements in the sport.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Sourav Ganguly\n",
            "\n",
            "Answer: Sourav Ganguly, also known as Dada, is a former Indian cricketer and captain of the Indian national team. He is considered one of the greatest captains in Indian cricket history and is known for his aggressive leadership style. Ganguly was a stylish left-handed batsman and a useful medium-pace bowler. He played a key role in shaping the Indian cricket team during his tenure as captain.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Joe Root\n",
            "\n",
            "Answer: Joe Root is an English cricketer who currently serves as the captain of the England national cricket team in Test matches. He is a right-handed batsman and occasional off-spin bowler. Root is known for his solid technique, elegant stroke play, and ability to score runs consistently. He has been a key player for England across all formats of the game and is considered one of the best batsmen in the world.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): list previous questions\n",
            "\n",
            "Answer: Sure! Here are the previous questions that have been asked:\n",
            "\n",
            "1. Who is SRT?\n",
            "2. Who is Sourav Ganguly?\n",
            "3. Who is Joe Root?\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #3 Chain + Memory"
      ],
      "metadata": {
        "id": "k7tTW7uC2gWH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import json\n",
        "\n",
        "# API key setup\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Helper functions to save/load memory\n",
        "\n",
        "def history_filename(topic):\n",
        "    # Sanitizing topic string for filename\n",
        "    safe_topic = topic.replace(\" \", \"_\").lower()\n",
        "    return f\"memory_{safe_topic}.json\"\n",
        "\n",
        "def load_memory(topic):\n",
        "    filename = history_filename(topic)\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            return json.load(f)  # expecting list of [question, answer] pairs\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def save_memory(topic, conversation_history):\n",
        "    filename = history_filename(topic)\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(conversation_history, f, indent=2)\n",
        "\n",
        "def format_history(history):\n",
        "    if not history:\n",
        "        return \"No previous Q&A.\"\n",
        "    formatted = \"\"\n",
        "    for i, (q, a) in enumerate(history[-5:], start=1):  # last 5 pairs\n",
        "        formatted += f\"Q{i}: {q}\\nA{i}: {a}\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "# ChatPromptTemplate including dynamic conversation history\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\n",
        "         \"You are a helpful assistant that answers questions about {topic}.\\n\"\n",
        "         \"Here is the recent conversation history:\\n\"\n",
        "         \"{history}\\n\"\n",
        "         \"Answer the next question carefully.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "chain = prompt | llm\n",
        "\n",
        "print(\"Welcome! You can ask questions on any topic.\")\n",
        "print(\"Type 'change topic' to switch topics or 'exit' to quit.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    topic = input(\"Enter the topic you'd like to ask about: \").strip()\n",
        "    if topic.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Load persistent conversation history for this topic\n",
        "    conversation_history = load_memory(topic)\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nAsk your question (or type 'change topic' or 'exit'): \").strip()\n",
        "        if question.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        elif question.lower() == 'change topic':\n",
        "            # Before switching, save current topic's conversation history\n",
        "            save_memory(topic, conversation_history)\n",
        "            break\n",
        "\n",
        "        history_text = format_history(conversation_history)\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"topic\": topic,\n",
        "            \"history\": history_text,\n",
        "            \"question\": question\n",
        "        })\n",
        "\n",
        "        answer = response.content\n",
        "        print(\"\\nAnswer:\", answer)\n",
        "\n",
        "        # Save Q&A pair to memory and persist immediately\n",
        "        conversation_history.append([question, answer])\n",
        "        save_memory(topic, conversation_history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpP1fbwm7j3I",
        "outputId": "e02bf2bf-861f-4fbc-d820-ce007f0f6b72"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! You can ask questions on any topic.\n",
            "Type 'change topic' to switch topics or 'exit' to quit.\n",
            "\n",
            "Enter the topic you'd like to ask about: cricket\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is SRT\n",
            "\n",
            "Answer: SRT stands for Sachin Ramesh Tendulkar, who is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. He is known for his numerous records and achievements in the sport.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Mr 360\n",
            "\n",
            "Answer: \"Mr. 360\" is a nickname given to AB de Villiers, a former South African cricketer known for his innovative and unorthodox batting style. He earned this nickname due to his ability to play shots all around the cricket field, showcasing his 360-degree range of strokes. AB de Villiers is considered one of the most talented and versatile batsmen in modern cricket.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who scored first ever double hundred in ODIs\n",
            "\n",
            "Answer: The first-ever double century in One Day International (ODI) cricket was scored by Sachin Tendulkar. He achieved this milestone on February 24, 2010, against South Africa in Gwalior, India. Sachin Tendulkar's innings of 200 not out remains a historic moment in cricket history.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): change topic\n",
            "Enter the topic you'd like to ask about: bollywood\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is SRK\n",
            "\n",
            "Answer: SRK is an abbreviation for Shah Rukh Khan, a famous Bollywood actor known as the \"King of Bollywood.\" He has starred in numerous successful films and is one of the most popular and influential actors in the Indian film industry.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Big B\n",
            "\n",
            "Answer: Big B is an affectionate nickname for Amitabh Bachchan, a legendary Bollywood actor who is considered one of the greatest and most influential actors in the history of Indian cinema. Amitabh Bachchan has been a prominent figure in Bollywood for several decades and has starred in numerous iconic films that have earned him a massive fan following.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): which are the bset movies of Big B\n",
            "\n",
            "Answer: Amitabh Bachchan has starred in many iconic and critically acclaimed movies throughout his career. Some of the best movies of Big B include:\n",
            "\n",
            "1. Sholay (1975) - A classic Bollywood film considered one of the greatest Indian films of all time.\n",
            "2. Deewaar (1975) - A crime drama that is highly regarded for its powerful performances and gripping storyline.\n",
            "3. Zanjeer (1973) - A film that established Amitabh Bachchan as the \"angry young man\" of Bollywood.\n",
            "4. Piku (2015) - A heartwarming comedy-drama that showcases Bachchan's versatility as an actor.\n",
            "5. Black (2005) - A poignant drama where Bachchan delivers a powerful performance as a teacher dealing with Alzheimer's disease.\n",
            "6. Agneepath (1990) - A cult classic where Bachchan plays a vengeful man seeking justice.\n",
            "7. Amar Akbar Anthony (1977) - A beloved Bollywood masala film with Bachchan in a memorable role.\n",
            "\n",
            "These are just a few examples of the many great movies in Amitabh Bachchan's filmography.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): show previous history\n",
            "\n",
            "Answer: Here is the recent conversation history:\n",
            "\n",
            "Q1: who is SRK\n",
            "A1: SRK is an abbreviation for Shah Rukh Khan, a famous Bollywood actor known as the \"King of Bollywood.\" He has starred in numerous successful films and is one of the most popular and influential actors in the Indian film industry.\n",
            "\n",
            "Q2: who is Big B\n",
            "A2: Big B is an affectionate nickname for Amitabh Bachchan, a legendary Bollywood actor who is considered one of the greatest and most influential actors in the history of Indian cinema. Amitabh Bachchan has been a prominent figure in Bollywood for several decades and has starred in numerous iconic films that have earned him a massive fan following.\n",
            "\n",
            "Q3: which are the bset movies of Big B\n",
            "A3: Amitabh Bachchan has starred in many iconic and critically acclaimed movies throughout his career. Some of the best movies of Big B include:\n",
            "\n",
            "1. Sholay (1975) - A classic Bollywood film considered one of the greatest Indian films of all time.\n",
            "2. Deewaar (1975) - A crime drama that is highly regarded for its powerful performances and gripping storyline.\n",
            "3. Zanjeer (1973) - A film that established Amitabh Bachchan as the \"angry young man\" of Bollywood.\n",
            "4. Piku (2015) - A heartwarming comedy-drama that showcases Bachchan's versatility as an actor.\n",
            "5. Black (2005) - A poignant drama where Bachchan delivers a powerful performance as a teacher dealing with Alzheimer's disease.\n",
            "6. Agneepath (1990) - A cult classic where Bachchan plays a vengeful man seeking justice.\n",
            "7. Amar Akbar Anthony (1977) - A beloved Bollywood masala film with Bachchan in a memorable role.\n",
            "\n",
            "These are just a few examples of the many great movies in Amitabh Bachchan's filmography.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): healthcare\n",
            "\n",
            "Answer: I'm here to help with questions related to Bollywood. If you have any queries about Bollywood actors, movies, or industry, feel free to ask!\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): what is paracetamol\n",
            "\n",
            "Answer: Paracetamol is a common over-the-counter medication used to relieve pain and reduce fever. It is also known as acetaminophen in some countries. Paracetamol is often used to alleviate mild to moderate pain from headaches, muscle aches, toothaches, and colds. It is generally considered safe when taken at the recommended dosage, but it's important to follow the instructions on the packaging or as advised by a healthcare professional.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): how imp walking or excercising\n",
            "\n",
            "Answer: Walking or exercising is very important for maintaining overall health and well-being. Regular physical activity, including walking and other forms of exercise, has numerous benefits such as:\n",
            "\n",
            "1. **Improving cardiovascular health:** Walking and exercising can help strengthen the heart, improve circulation, and lower the risk of heart diseases.\n",
            "\n",
            "2. **Weight management:** Regular physical activity can help in managing weight by burning calories and increasing metabolism.\n",
            "\n",
            "3. **Boosting mood:** Exercise releases endorphins, also known as \"feel-good\" hormones, which can help reduce feelings of stress, anxiety, and depression.\n",
            "\n",
            "4. **Increasing energy levels:** Physical activity can improve stamina and energy levels, making daily tasks easier to accomplish.\n",
            "\n",
            "5. **Enhancing muscle strength and flexibility:** Walking and exercising can help build and tone muscles, improve flexibility, and maintain bone density.\n",
            "\n",
            "6. **Improving overall health:** Regular physical activity can lower the risk of chronic diseases such as diabetes, hypertension, and certain types of cancer.\n",
            "\n",
            "It is recommended to engage in at least 150 minutes of moderate-intensity aerobic activity per week, along with muscle-strengthening activities on two or more days a week. However, it's essential to consult with a healthcare professional before starting any new exercise routine, especially if you have any underlying health conditions.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): change topic\n",
            "Enter the topic you'd like to ask about: bollywood\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): do u remember about Big B WHAT INFO U GAVE EARLIER\n",
            "\n",
            "Answer: Earlier, I provided information about Amitabh Bachchan, also known as Big B, who is a legendary Bollywood actor considered one of the greatest and most influential actors in Indian cinema. I mentioned some of the best movies of Big B, including \"Sholay,\" \"Deewaar,\" \"Zanjeer,\" \"Piku,\" \"Black,\" \"Agneepath,\" and \"Amar Akbar Anthony.\" Amitabh Bachchan has had a remarkable career in Bollywood, starring in numerous iconic and critically acclaimed films that have solidified his status as a cinematic legend. If you have any more questions about Big B or Bollywood in general, feel free to ask!\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): change topic\n",
            "Enter the topic you'd like to ask about: travel\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): whar are the laces to visit in goa\n",
            "\n",
            "Answer: There are many wonderful places to visit in Goa, India. Some popular attractions include:\n",
            "\n",
            "1. Beaches: Goa is famous for its beautiful beaches such as Baga Beach, Calangute Beach, Anjuna Beach, and Palolem Beach.\n",
            "\n",
            "2. Old Goa: Visit the historic churches and cathedrals in Old Goa, including Basilica of Bom Jesus and Se Cathedral.\n",
            "\n",
            "3. Fort Aguada: Explore this well-preserved 17th-century Portuguese fort with stunning views of the Arabian Sea.\n",
            "\n",
            "4. Dudhsagar Waterfalls: Take a trip to see the majestic Dudhsagar Waterfalls, one of the tallest waterfalls in India.\n",
            "\n",
            "5. Spice Plantations: Experience the sights and smells of Goa's spice plantations on a guided tour.\n",
            "\n",
            "6. Panaji: Explore the charming capital city of Goa, known for its colorful buildings, markets, and Portuguese-influenced architecture.\n",
            "\n",
            "These are just a few of the many places to visit in Goa. Enjoy your trip!\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): give me 10 places\n",
            "\n",
            "Answer: Sure! Here are 10 places to visit in Goa, India:\n",
            "\n",
            "1. Baga Beach\n",
            "2. Calangute Beach\n",
            "3. Anjuna Beach\n",
            "4. Palolem Beach\n",
            "5. Basilica of Bom Jesus\n",
            "6. Se Cathedral\n",
            "7. Fort Aguada\n",
            "8. Dudhsagar Waterfalls\n",
            "9. Spice Plantations\n",
            "10. Panaji\n",
            "\n",
            "These are some of the top attractions in Goa that you can explore and enjoy during your visit. Have a great trip!\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #4 -> with history (MessagesPlaceHolder & Buffer Memory)"
      ],
      "metadata": {
        "id": "wV0GW10g7j1C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.runnables import Runnable\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set API key (adjust if not in Colab)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# --- Helper: in-memory memory store per topic ---\n",
        "# For persistence across script restarts, you could save/load memory states to disk or DB.\n",
        "# Here we just keep in RAM for demonstration.\n",
        "\n",
        "memory_store = {}\n",
        "\n",
        "def get_memory_for_topic(topic):\n",
        "    if topic not in memory_store:\n",
        "        # Initialize a new memory instance for each topic\n",
        "        memory_store[topic] = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "    return memory_store[topic]\n",
        "\n",
        "# --- Define prompt with MessagesPlaceholder ---\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),  # Inject chat history here automatically\n",
        "        (\"human\", \"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Create a chain composed of prompt followed by llm\n",
        "chain = prompt | llm\n",
        "\n",
        "print(\"Welcome! You can ask questions on any topic.\")\n",
        "print(\"Type 'change topic' to switch topics or 'exit' to quit.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    topic = input(\"Enter the topic you'd like to ask about: \").strip()\n",
        "    if topic.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Get (or create) memory for this topic\n",
        "    memory = get_memory_for_topic(topic)\n",
        "\n",
        "    # We'll associate the current Topic variable to memory as context below\n",
        "    while True:\n",
        "        question = input(\"\\nAsk your question (or type 'change topic' or 'exit'): \").strip()\n",
        "        if question.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        if question.lower() == 'change topic':\n",
        "            print(f\"Switching from topic '{topic}'\\n\")\n",
        "            break\n",
        "\n",
        "        # Prepare inputs including memory context\n",
        "        inputs = {\n",
        "            \"topic\": topic,\n",
        "            \"question\": question,\n",
        "            \"history\": memory.load_memory_variables({}).get(\"history\", [])  # load_messages from memory\n",
        "        }\n",
        "\n",
        "        # Invoke chain with inputs; chain sees 'history' as part of MessagesPlaceholder\n",
        "        response = chain.invoke(inputs)\n",
        "\n",
        "        # Print the assistant's reply\n",
        "        print(\"\\nAnswer:\", response.content)\n",
        "\n",
        "        # Save conversation turns to memory\n",
        "        # Add user's question message\n",
        "        memory.save_context({\"human\": question}, {\"ai\": response.content})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuNUNxdZ7jye",
        "outputId": "0fdff52e-aace-4ece-fa35-7f184da53e14"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome! You can ask questions on any topic.\n",
            "Type 'change topic' to switch topics or 'exit' to quit.\n",
            "\n",
            "Enter the topic you'd like to ask about: cricket\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-2664389394.py:20: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory_store[topic] = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is SRT\n",
            "\n",
            "Answer: SRT stands for Sachin Ramesh Tendulkar, who is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. He is also known as the \"Master Blaster\" and \"Little Master.\" Tendulkar holds numerous records in international cricket and is considered a legend in the sport.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Brian Lara\n",
            "\n",
            "Answer: Brian Lara is a former West Indian cricketer who is considered one of the greatest batsmen in the history of the sport. He holds several records, including the highest individual score in Test cricket (400 not out) and the highest first-class score (501 not out). Lara was known for his elegant stroke play and ability to dominate bowling attacks. He is a cricketing legend and is widely respected for his achievements in the game.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is Sanath Jayasurya\n",
            "\n",
            "Answer: Sanath Jayasuriya is a former Sri Lankan cricketer who is considered one of the greatest all-rounders in the history of the sport. He was known for his aggressive batting at the top of the order and his left-arm spin bowling. Jayasuriya played a key role in revolutionizing the role of the opening batsman in limited-overs cricket with his attacking style of play. He was a key player in Sri Lanka's 1996 World Cup-winning team and had a successful international career spanning over two decades.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): who is first captain to win world cup for Srilanks in ODIs\n",
            "\n",
            "Answer: Arjuna Ranatunga was the first captain to lead Sri Lanka to victory in the ICC Cricket World Cup in 1996. Under his leadership, Sri Lanka defeated Australia in the final to win their first-ever World Cup title. Ranatunga is credited for his tactical acumen and leadership skills in guiding the team to this historic victory.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): can u give me history of all prompts\n",
            "\n",
            "Answer: I'm sorry, but I don't have access to the history of all prompts. I am designed to provide information and assistance on a wide range of topics, including cricket. If you have any specific questions about cricket or any other topic, feel free to ask, and I'll do my best to help you.\n",
            "\n",
            "Ask your question (or type 'change topic' or 'exit'): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Conversation History ---\")\n",
        "for msg in memory.load_memory_variables({}).get(\"history\", []):\n",
        "    print(f\"[{msg.type}] {msg.content}\")\n",
        "print(\"----------------------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1XoOSiGIIiN",
        "outputId": "3fc83df0-d098-45eb-8cd7-e70982637af9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Conversation History ---\n",
            "[human] who is SRT\n",
            "[ai] SRT stands for Sachin Ramesh Tendulkar, who is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. He is also known as the \"Master Blaster\" and \"Little Master.\" Tendulkar holds numerous records in international cricket and is considered a legend in the sport.\n",
            "[human] who is Brian Lara\n",
            "[ai] Brian Lara is a former West Indian cricketer who is considered one of the greatest batsmen in the history of the sport. He holds several records, including the highest individual score in Test cricket (400 not out) and the highest first-class score (501 not out). Lara was known for his elegant stroke play and ability to dominate bowling attacks. He is a cricketing legend and is widely respected for his achievements in the game.\n",
            "[human] who is Sanath Jayasurya\n",
            "[ai] Sanath Jayasuriya is a former Sri Lankan cricketer who is considered one of the greatest all-rounders in the history of the sport. He was known for his aggressive batting at the top of the order and his left-arm spin bowling. Jayasuriya played a key role in revolutionizing the role of the opening batsman in limited-overs cricket with his attacking style of play. He was a key player in Sri Lanka's 1996 World Cup-winning team and had a successful international career spanning over two decades.\n",
            "[human] who is first captain to win world cup for Srilanks in ODIs\n",
            "[ai] Arjuna Ranatunga was the first captain to lead Sri Lanka to victory in the ICC Cricket World Cup in 1996. Under his leadership, Sri Lanka defeated Australia in the final to win their first-ever World Cup title. Ranatunga is credited for his tactical acumen and leadership skills in guiding the team to this historic victory.\n",
            "[human] can u give me history of all prompts\n",
            "[ai] I'm sorry, but I don't have access to the history of all prompts. I am designed to provide information and assistance on a wide range of topics, including cricket. If you have any specific questions about cricket or any other topic, feel free to ask, and I'll do my best to help you.\n",
            "----------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #5 - Persistent Memory Management (using Manual Session-ID)"
      ],
      "metadata": {
        "id": "jcxRe099IIYD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your API key (adjust if not in Colab)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# --- Persistent Memory Helpers (per session and topic) ---\n",
        "\n",
        "def make_memory_filename(session_id: str, topic: str) -> str:\n",
        "    safe_session = session_id.replace(\" \", \"_\").lower()\n",
        "    safe_topic = topic.replace(\" \", \"_\").lower()\n",
        "    return f\"memory_{safe_session}_{safe_topic}.json\"\n",
        "\n",
        "def save_memory_to_file(conversation_history, filename):\n",
        "    # conversation_history: list of messages (dict form)\n",
        "    # Save messages as list of dicts\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(conversation_history, f, indent=2)\n",
        "\n",
        "def load_memory_from_file(filename):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "def convert_msgs_for_memory(messages_json):\n",
        "    \"\"\"Convert loaded JSON into LangChain Message objects\"\"\"\n",
        "    from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "    msg_list = []\n",
        "    for msg in messages_json:\n",
        "        # Each msg is a dict with \"type\" and \"content\"\n",
        "        t = msg.get(\"type\")\n",
        "        c = msg.get(\"content\")\n",
        "        if t == \"human\":\n",
        "            msg_list.append(HumanMessage(content=c))\n",
        "        elif t == \"ai\":\n",
        "            msg_list.append(AIMessage(content=c))\n",
        "        elif t == \"system\":\n",
        "            msg_list.append(SystemMessage(content=c))\n",
        "        else:\n",
        "            # Default fallback\n",
        "            msg_list.append(HumanMessage(content=c))\n",
        "    return msg_list\n",
        "\n",
        "def convert_msgs_to_json(messages):\n",
        "    \"\"\"Convert LangChain Message objects to simple JSON serializable dicts\"\"\"\n",
        "    json_list = []\n",
        "    for msg in messages:\n",
        "        # msg.type can be 'human', 'ai', 'system'\n",
        "        json_list.append({\n",
        "            \"type\": msg.type,\n",
        "            \"content\": msg.content\n",
        "        })\n",
        "    return json_list\n",
        "\n",
        "# --- Session & Topic Memory Management ---\n",
        "\n",
        "# Maintain in-memory ConversationBufferMemory instances per session & topic\n",
        "memory_store = {}\n",
        "\n",
        "def get_memory(session_id, topic):\n",
        "    key = (session_id, topic)\n",
        "    if key in memory_store:\n",
        "        return memory_store[key]\n",
        "\n",
        "    # Else create new memory and try loading stored history from disk\n",
        "    memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "\n",
        "    # Load history from file if exists\n",
        "    filename = make_memory_filename(session_id, topic)\n",
        "    loaded_msgs_json = load_memory_from_file(filename)\n",
        "    if loaded_msgs_json:\n",
        "        # Convert JSON back to LangChain Messages and set memory state manually\n",
        "        from langchain.memory.chat_memory import _messages_from_dict\n",
        "        # Instead of _messages_from_dict (private), we use convert_msgs_for_memory here\n",
        "        loaded_msgs = convert_msgs_for_memory(loaded_msgs_json)\n",
        "        memory.chat_memory.messages = loaded_msgs\n",
        "\n",
        "    memory_store[key] = memory\n",
        "    return memory\n",
        "\n",
        "def save_memory(session_id, topic, memory):\n",
        "    filename = make_memory_filename(session_id, topic)\n",
        "    # Extract messages and convert them to JSON serializable form\n",
        "    messages = memory.load_memory_variables({}).get(\"history\", [])\n",
        "    msgs_json = convert_msgs_to_json(messages)\n",
        "    save_memory_to_file(msgs_json, filename)\n",
        "\n",
        "\n",
        "# --- Prompt and Chain Setup ---\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),  # Automatically insert conversation history\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "chain = prompt | llm\n",
        "\n",
        "# --- Main conversational loop with sessions and topics ---\n",
        "\n",
        "print(\"Welcome! This chat supports multiple sessions & topics with persistent memory.\")\n",
        "print(\"Type 'exit' to quit at any prompt.\")\n",
        "print(\"Type 'change topic' during questioning to pick a new topic.\")\n",
        "print(\"Type 'show history' during questioning to display conversation history.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    session_id = input(\"Enter your session id (e.g. user name or unique ID): \").strip()\n",
        "    if session_id.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    while True:\n",
        "        topic = input(f\"Enter the topic for session '{session_id}': \").strip()\n",
        "        if topic.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        if not topic:\n",
        "            print(\"Please enter a valid topic.\")\n",
        "            continue\n",
        "\n",
        "        # Get memory object for session + topic\n",
        "        memory = get_memory(session_id, topic)\n",
        "\n",
        "        # Conversation loop per topic & session\n",
        "        while True:\n",
        "            question = input(f\"\\n[{session_id} | {topic}] Ask a question ('change topic', 'show history', 'exit'): \").strip()\n",
        "            lower_q = question.lower()\n",
        "\n",
        "            if lower_q in ['exit', 'quit']:\n",
        "                # Save memory and exit everything\n",
        "                save_memory(session_id, topic, memory)\n",
        "                print(\"Goodbye!\")\n",
        "                run = False\n",
        "                break\n",
        "            elif lower_q == 'change topic':\n",
        "                # Save memory and break to outer topic selection\n",
        "                save_memory(session_id, topic, memory)\n",
        "                print(f\"Changing topic from '{topic}'\\n\")\n",
        "                break\n",
        "            elif lower_q == 'show history':\n",
        "                # Show current conversation history nicely\n",
        "                msgs = memory.load_memory_variables({}).get(\"history\", [])\n",
        "                if not msgs:\n",
        "                    print(\"\\nNo conversation history yet.\")\n",
        "                else:\n",
        "                    print(\"\\n--- Conversation History ---\")\n",
        "                    for i, msg in enumerate(msgs, start=1):\n",
        "                        role = \"User\" if msg.type == \"human\" else \"Assistant\" if msg.type == \"ai\" else \"System\"\n",
        "                        print(f\"{i}. {role}: {msg.content}\")\n",
        "                    print(\"----------------------------\\n\")\n",
        "                continue\n",
        "\n",
        "            # Run chain with current inputs + memory\n",
        "            inputs = {\n",
        "                \"topic\": topic,\n",
        "                \"question\": question,\n",
        "                \"history\": memory.load_memory_variables({}).get(\"history\", [])\n",
        "            }\n",
        "\n",
        "            response = chain.invoke(inputs)\n",
        "            answer = response.content\n",
        "            print(\"\\nAnswer:\", answer)\n",
        "\n",
        "            # Save context to memory and persist state\n",
        "            memory.save_context({\"human\": question}, {\"ai\": answer})\n",
        "            save_memory(session_id, topic, memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2f_VINWIINo",
        "outputId": "297c5247-2513-4194-fa97-84e0da7cedbe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! This chat supports multiple sessions & topics with persistent memory.\n",
            "Type 'exit' to quit at any prompt.\n",
            "Type 'change topic' during questioning to pick a new topic.\n",
            "Type 'show history' during questioning to display conversation history.\n",
            "\n",
            "Enter your session id (e.g. user name or unique ID): sn17\n",
            "Enter the topic for session 'sn17': cricket\n",
            "\n",
            "[sn17 | cricket] Ask a question ('change topic', 'show history', 'exit'): who is SRT\n",
            "\n",
            "Answer: SRT stands for Sachin Ramesh Tendulkar, who is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. He is also known as the \"Master Blaster\" and \"Little Master.\" Sachin Tendulkar holds numerous records in international cricket and is considered a legend in the sport.\n",
            "\n",
            "[sn17 | cricket] Ask a question ('change topic', 'show history', 'exit'): Who is Arjuna Ranatunga\n",
            "\n",
            "Answer: Arjuna Ranatunga is a former Sri Lankan cricketer who is best known for leading the Sri Lankan cricket team to their first-ever Cricket World Cup victory in 1996. He was a left-handed batsman and a medium-pace bowler who played a key role in the development of Sri Lankan cricket during his career. Ranatunga is also a former politician and served as the Minister of Ports and Shipping in Sri Lanka.\n",
            "\n",
            "[sn17 | cricket] Ask a question ('change topic', 'show history', 'exit'): show history\n",
            "\n",
            "--- Conversation History ---\n",
            "1. User: who is SRT\n",
            "2. Assistant: SRT stands for Sachin Ramesh Tendulkar, who is a former Indian cricketer widely regarded as one of the greatest batsmen in the history of cricket. He is also known as the \"Master Blaster\" and \"Little Master.\" Sachin Tendulkar holds numerous records in international cricket and is considered a legend in the sport.\n",
            "3. User: Who is Arjuna Ranatunga\n",
            "4. Assistant: Arjuna Ranatunga is a former Sri Lankan cricketer who is best known for leading the Sri Lankan cricket team to their first-ever Cricket World Cup victory in 1996. He was a left-handed batsman and a medium-pace bowler who played a key role in the development of Sri Lankan cricket during his career. Ranatunga is also a former politician and served as the Minister of Ports and Shipping in Sri Lanka.\n",
            "----------------------------\n",
            "\n",
            "\n",
            "[sn17 | cricket] Ask a question ('change topic', 'show history', 'exit'): exit\n",
            "Goodbye!\n",
            "Enter the topic for session 'sn17': exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #6 - Persistent Memory Management (using System Generated Session-ID)"
      ],
      "metadata": {
        "id": "PEWZ2lSGM7jn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "import json\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata  # Remove if not running in Colab\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# --- Persistent Memory Helpers (per session and topic) ---\n",
        "\n",
        "def make_memory_filename(session_id: str, topic: str) -> str:\n",
        "    safe_session = session_id.replace(\" \", \"_\").lower()\n",
        "    safe_topic = topic.replace(\" \", \"_\").lower()\n",
        "    return f\"memory_{safe_session}_{safe_topic}.json\"\n",
        "\n",
        "def save_memory_to_file(conversation_history, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(conversation_history, f, indent=2)\n",
        "\n",
        "def load_memory_from_file(filename):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "def convert_msgs_for_memory(messages_json):\n",
        "    from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "    msg_list = []\n",
        "    for msg in messages_json:\n",
        "        t = msg.get(\"type\")\n",
        "        c = msg.get(\"content\")\n",
        "        if t == \"human\":\n",
        "            msg_list.append(HumanMessage(content=c))\n",
        "        elif t == \"ai\":\n",
        "            msg_list.append(AIMessage(content=c))\n",
        "        elif t == \"system\":\n",
        "            msg_list.append(SystemMessage(content=c))\n",
        "        else:\n",
        "            msg_list.append(HumanMessage(content=c))\n",
        "    return msg_list\n",
        "\n",
        "def convert_msgs_to_json(messages):\n",
        "    json_list = []\n",
        "    for msg in messages:\n",
        "        json_list.append({\n",
        "            \"type\": msg.type,\n",
        "            \"content\": msg.content\n",
        "        })\n",
        "    return json_list\n",
        "\n",
        "# --- Session & Topic Memory Management ---\n",
        "\n",
        "memory_store = {}\n",
        "\n",
        "def get_memory(session_id, topic):\n",
        "    key = (session_id, topic)\n",
        "    if key in memory_store:\n",
        "        return memory_store[key]\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "    filename = make_memory_filename(session_id, topic)\n",
        "    loaded_msgs_json = load_memory_from_file(filename)\n",
        "    if loaded_msgs_json:\n",
        "        loaded_msgs = convert_msgs_for_memory(loaded_msgs_json)\n",
        "        memory.chat_memory.messages = loaded_msgs\n",
        "\n",
        "    memory_store[key] = memory\n",
        "    return memory\n",
        "\n",
        "def save_memory(session_id, topic, memory):\n",
        "    filename = make_memory_filename(session_id, topic)\n",
        "    messages = memory.load_memory_variables({}).get(\"history\", [])\n",
        "    msgs_json = convert_msgs_to_json(messages)\n",
        "    save_memory_to_file(msgs_json, filename)\n",
        "\n",
        "\n",
        "# --- Prompt and Chain Setup ---\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),  # Inject conversation history\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "chain = prompt | llm\n",
        "\n",
        "\n",
        "# --- Main conversational loop with session id generation ---\n",
        "\n",
        "print(\"Welcome! This chat supports multiple sessions & topics with persistent memory.\")\n",
        "print(\"Type 'exit' to quit at any prompt.\")\n",
        "print(\"Type 'change topic' during questioning to pick a new topic.\")\n",
        "print(\"Type 'show history' during questioning to display conversation history.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    session_id = input(\"Enter your session id (leave blank for auto-generated): \").strip()\n",
        "    if session_id.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    if not session_id:\n",
        "        session_id = str(uuid.uuid4())\n",
        "        print(f\"Your generated session id: {session_id}\")\n",
        "\n",
        "    while True:\n",
        "        topic = input(f\"Enter the topic for session '{session_id}': \").strip()\n",
        "        if topic.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        if not topic:\n",
        "            print(\"Please enter a valid topic.\")\n",
        "            continue\n",
        "\n",
        "        memory = get_memory(session_id, topic)\n",
        "\n",
        "        while True:\n",
        "            question = input(f\"\\n[{session_id} | {topic}] Ask a question ('change topic', 'show history', 'exit'): \").strip()\n",
        "            lower_q = question.lower()\n",
        "\n",
        "            if lower_q in ['exit', 'quit']:\n",
        "                save_memory(session_id, topic, memory)\n",
        "                print(\"Goodbye!\")\n",
        "                run = False\n",
        "                break\n",
        "            elif lower_q == 'change topic':\n",
        "                save_memory(session_id, topic, memory)\n",
        "                print(f\"Changing topic from '{topic}'\\n\")\n",
        "                break\n",
        "            elif lower_q == 'show history':\n",
        "                msgs = memory.load_memory_variables({}).get(\"history\", [])\n",
        "                if not msgs:\n",
        "                    print(\"\\nNo conversation history yet.\")\n",
        "                else:\n",
        "                    print(\"\\n--- Conversation History ---\")\n",
        "                    for i, msg in enumerate(msgs, start=1):\n",
        "                        role = \"User\" if msg.type == \"human\" else \"Assistant\" if msg.type == \"ai\" else \"System\"\n",
        "                        print(f\"{i}. {role}: {msg.content}\")\n",
        "                    print(\"----------------------------\\n\")\n",
        "                continue\n",
        "\n",
        "            inputs = {\n",
        "                \"topic\": topic,\n",
        "                \"question\": question,\n",
        "                \"history\": memory.load_memory_variables({}).get(\"history\", [])\n",
        "            }\n",
        "\n",
        "            response = chain.invoke(inputs)\n",
        "            answer = response.content\n",
        "            print(\"\\nAnswer:\", answer)\n",
        "\n",
        "            memory.save_context({\"human\": question}, {\"ai\": answer})\n",
        "            save_memory(session_id, topic, memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqZZf1v9M7i0",
        "outputId": "2d8fb718-3492-4b64-b420-5dfce961ccca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! This chat supports multiple sessions & topics with persistent memory.\n",
            "Type 'exit' to quit at any prompt.\n",
            "Type 'change topic' during questioning to pick a new topic.\n",
            "Type 'show history' during questioning to display conversation history.\n",
            "\n",
            "Enter your session id (leave blank for auto-generated): \n",
            "Your generated session id: 677f6f65-7e6b-4707-8bd2-8895058758f1\n",
            "Enter the topic for session '677f6f65-7e6b-4707-8bd2-8895058758f1': general\n",
            "\n",
            "[677f6f65-7e6b-4707-8bd2-8895058758f1 | general] Ask a question ('change topic', 'show history', 'exit'): show history\n",
            "\n",
            "No conversation history yet.\n",
            "\n",
            "[677f6f65-7e6b-4707-8bd2-8895058758f1 | general] Ask a question ('change topic', 'show history', 'exit'): exit\n",
            "Goodbye!\n",
            "Enter the topic for session '677f6f65-7e6b-4707-8bd2-8895058758f1': exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example #7 -> Write history to csv"
      ],
      "metadata": {
        "id": "snphJGDNM7ND"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "import json\n",
        "import csv\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata  # Remove or replace if not in Colab\n",
        "\n",
        "# Set your OpenAI API key from Colab userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# --- Persistent Memory Helpers (per session and topic) ---\n",
        "\n",
        "def make_memory_filename(session_id: str, topic: str) -> str:\n",
        "    safe_session = session_id.replace(\" \", \"_\").lower()\n",
        "    safe_topic = topic.replace(\" \", \"_\").lower()\n",
        "    return f\"memory_{safe_session}_{safe_topic}.json\"\n",
        "\n",
        "def save_memory_to_file(conversation_history, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(conversation_history, f, indent=2)\n",
        "\n",
        "def load_memory_from_file(filename):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "def convert_msgs_for_memory(messages_json):\n",
        "    from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "    msg_list = []\n",
        "    for msg in messages_json:\n",
        "        t = msg.get(\"type\")\n",
        "        c = msg.get(\"content\")\n",
        "        if t == \"human\":\n",
        "            msg_list.append(HumanMessage(content=c))\n",
        "        elif t == \"ai\":\n",
        "            msg_list.append(AIMessage(content=c))\n",
        "        elif t == \"system\":\n",
        "            msg_list.append(SystemMessage(content=c))\n",
        "        else:\n",
        "            msg_list.append(HumanMessage(content=c))\n",
        "    return msg_list\n",
        "\n",
        "def convert_msgs_to_json(messages):\n",
        "    json_list = []\n",
        "    for msg in messages:\n",
        "        json_list.append({\n",
        "            \"type\": msg.type,\n",
        "            \"content\": msg.content\n",
        "        })\n",
        "    return json_list\n",
        "\n",
        "# --- CSV export helper ---\n",
        "\n",
        "def save_history_to_csv(history_messages, csv_filename):\n",
        "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Index\", \"Role\", \"Content\"])\n",
        "        for i, msg in enumerate(history_messages, start=1):\n",
        "            if msg.type == \"human\":\n",
        "                role = \"User\"\n",
        "            elif msg.type == \"ai\":\n",
        "                role = \"Assistant\"\n",
        "            elif msg.type == \"system\":\n",
        "                role = \"System\"\n",
        "            else:\n",
        "                role = msg.type.capitalize()\n",
        "            writer.writerow([i, role, msg.content])\n",
        "    print(f\"Conversation history saved to {csv_filename}\")\n",
        "\n",
        "# --- Session & Topic Memory Management ---\n",
        "\n",
        "memory_store = {}\n",
        "\n",
        "def get_memory(session_id, topic):\n",
        "    key = (session_id, topic)\n",
        "    if key in memory_store:\n",
        "        return memory_store[key]\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "    filename = make_memory_filename(session_id, topic)\n",
        "    loaded_msgs_json = load_memory_from_file(filename)\n",
        "    if loaded_msgs_json:\n",
        "        loaded_msgs = convert_msgs_for_memory(loaded_msgs_json)\n",
        "        memory.chat_memory.messages = loaded_msgs\n",
        "\n",
        "    memory_store[key] = memory\n",
        "    return memory\n",
        "\n",
        "def save_memory(session_id, topic, memory):\n",
        "    filename = make_memory_filename(session_id, topic)\n",
        "    messages = memory.load_memory_variables({}).get(\"history\", [])\n",
        "    msgs_json = convert_msgs_to_json(messages)\n",
        "    save_memory_to_file(msgs_json, filename)\n",
        "\n",
        "# --- Prompt and Chain Setup ---\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "chain = prompt | llm\n",
        "\n",
        "# --- Main conversational loop with session ID and commands ---\n",
        "\n",
        "print(\"Welcome! This chat supports multiple sessions & topics with persistent memory.\")\n",
        "print(\"Commands during questioning: 'change topic', 'show history', 'export history', 'exit'.\\n\")\n",
        "\n",
        "run = True\n",
        "while run:\n",
        "    session_id = input(\"Enter your session id (leave blank to auto-generate): \").strip()\n",
        "    if session_id.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    if not session_id:\n",
        "        session_id = str(uuid.uuid4())\n",
        "        print(f\"Your generated session id: {session_id}\")\n",
        "\n",
        "    while True:\n",
        "        topic = input(f\"\\nEnter the topic for session '{session_id}': \").strip()\n",
        "        if topic.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            run = False\n",
        "            break\n",
        "        if not topic:\n",
        "            print(\"Please enter a valid topic.\")\n",
        "            continue\n",
        "\n",
        "        memory = get_memory(session_id, topic)\n",
        "\n",
        "        while True:\n",
        "            question = input(f\"\\n[{session_id} | {topic}] Ask a question ('change topic', 'show history', 'export history', 'exit'): \").strip()\n",
        "            lower_q = question.lower()\n",
        "\n",
        "            if lower_q in ['exit', 'quit']:\n",
        "                save_memory(session_id, topic, memory)\n",
        "                print(\"Goodbye!\")\n",
        "                run = False\n",
        "                break\n",
        "            elif lower_q == 'change topic':\n",
        "                save_memory(session_id, topic, memory)\n",
        "                print(f\"Switching topic from '{topic}'...\\n\")\n",
        "                break\n",
        "            elif lower_q == 'show history':\n",
        "                msgs = memory.load_memory_variables({}).get(\"history\", [])\n",
        "                if not msgs:\n",
        "                    print(\"\\nNo conversation history yet.\")\n",
        "                else:\n",
        "                    print(\"\\n--- Conversation History ---\")\n",
        "                    for i, msg in enumerate(msgs, start=1):\n",
        "                        role = \"User\" if msg.type == \"human\" else \"Assistant\" if msg.type == \"ai\" else \"System\"\n",
        "                        print(f\"{i}. {role}: {msg.content}\")\n",
        "                    print(\"----------------------------\\n\")\n",
        "                continue\n",
        "            elif lower_q == 'export history':\n",
        "                msgs = memory.load_memory_variables({}).get(\"history\", [])\n",
        "                filename = f\"history_{session_id}_{topic}.csv\".replace(\" \", \"_\")\n",
        "                save_history_to_csv(msgs, filename)\n",
        "                continue\n",
        "\n",
        "            inputs = {\n",
        "                \"topic\": topic,\n",
        "                \"question\": question,\n",
        "                \"history\": memory.load_memory_variables({}).get(\"history\", [])\n",
        "            }\n",
        "\n",
        "            response = chain.invoke(inputs)\n",
        "            answer = response.content\n",
        "            print(\"\\nAnswer:\", answer)\n",
        "\n",
        "            memory.save_context({\"human\": question}, {\"ai\": answer})\n",
        "            save_memory(session_id, topic, memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5i6aIjbM7LL",
        "outputId": "376fae12-548e-4707-9e53-e5a03c558ba1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! This chat supports multiple sessions & topics with persistent memory.\n",
            "Commands during questioning: 'change topic', 'show history', 'export history', 'exit'.\n",
            "\n",
            "Enter your session id (leave blank to auto-generate): 111\n",
            "\n",
            "Enter the topic for session '111': cricket\n",
            "\n",
            "[111 | cricket] Ask a question ('change topic', 'show history', 'export history', 'exit'): who was the first captain to win ODI world cup for SriLanka\n",
            "\n",
            "Answer: Arjuna Ranatunga was the first captain to lead Sri Lanka to victory in the ODI World Cup in 1996.\n",
            "\n",
            "[111 | cricket] Ask a question ('change topic', 'show history', 'export history', 'exit'): and for India?\n",
            "\n",
            "Answer: Kapil Dev was the captain of the Indian cricket team when they won their first ODI World Cup in 1983.\n",
            "\n",
            "[111 | cricket] Ask a question ('change topic', 'show history', 'export history', 'exit'): and ofr India in Y20s?\n",
            "\n",
            "Answer: Mahendra Singh Dhoni was the captain of the Indian cricket team when they won the ICC T20 World Cup in 2007.\n",
            "\n",
            "[111 | cricket] Ask a question ('change topic', 'show history', 'export history', 'exit'): and for Australlia in T20s?\n",
            "\n",
            "Answer: Aaron Finch was the captain of the Australian cricket team when they won the ICC T20 World Cup in 2021.\n",
            "\n",
            "[111 | cricket] Ask a question ('change topic', 'show history', 'export history', 'exit'): and For SriLanka?\n",
            "\n",
            "Answer: Lasith Malinga was the captain of the Sri Lankan cricket team when they won the ICC T20 World Cup in 2014.\n",
            "\n",
            "[111 | cricket] Ask a question ('change topic', 'show history', 'export history', 'exit'): exit\n",
            "Goodbye!\n",
            "\n",
            "Enter the topic for session '111': exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UI - Implementation with Gradio"
      ],
      "metadata": {
        "id": "xknhe-uWM7Kk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UI Implementation"
      ],
      "metadata": {
        "id": "EOYDvdL1ykcx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat-bot with Gradio"
      ],
      "metadata": {
        "id": "QBm4JFdP_-GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below"
      ],
      "metadata": {
        "id": "sgxLzbf9AB6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 1: Install dependencies\n",
        "!pip install --quiet langchain openai gradio\n",
        "\n",
        "# ✅ STEP 2: Imports\n",
        "import gradio as gr\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# ✅ STEP 3: Setup OpenAI key securely\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# ✅ STEP 4: Initialize OpenAI LLM\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# ✅ STEP 5: Define the chatbot function\n",
        "def chatbot_fn(topic, question):\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that answers questions about {topic}.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "    ])\n",
        "    messages = prompt.format_messages(topic=topic, question=question)\n",
        "    response = llm.invoke(messages)\n",
        "    return response.content\n",
        "\n",
        "# ✅ STEP 6: Launch Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### 🤖 OpenAI Chatbot (LangChain + Gradio in Colab)\")\n",
        "    topic = gr.Textbox(label=\"Topic\", placeholder=\"e.g. Healthcare, Cricket\")\n",
        "    question = gr.Textbox(label=\"Your Question\", placeholder=\"Ask your question...\")\n",
        "    response = gr.Textbox(label=\"Response\")\n",
        "    ask_btn = gr.Button(\"Ask\")\n",
        "    ask_btn.click(fn=chatbot_fn, inputs=[topic, question], outputs=response)\n",
        "\n",
        "demo.launch(share=True)  # use share=True to expose public link in Colab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "jCw41ENsACw9",
        "outputId": "7828f211-318b-4f34-ce67-67f4cd51c206"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bd2ff4a2186178cb66.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bd2ff4a2186178cb66.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgletWe5ADS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}